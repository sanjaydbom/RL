{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-5\n",
    "theta = [0,0] # left, right\n",
    "num_episodes = 1000\n",
    "gamma = 1\n",
    "max_steps_per_episode = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.014529420706278237, -0.6211821304632986]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    # returns probability of going left\n",
    "    return math.exp(x[0]) / sum([math.exp(i) for i in x])\n",
    "\n",
    "def get_action(t=theta):\n",
    "    if random.random() < softmax(t):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def next_state(state, action):\n",
    "    if state == 1:\n",
    "        return state - action\n",
    "    else:\n",
    "        return max(0, state + action)\n",
    "for _ in range(num_episodes):\n",
    "    num_steps = 0\n",
    "    episode = []\n",
    "    state = 0\n",
    "    while num_steps < max_steps_per_episode:\n",
    "        num_steps += 1\n",
    "        action = get_action()\n",
    "        state = next_state(state, action)\n",
    "        if state == 3:\n",
    "            episode.append((action,1))\n",
    "            break\n",
    "        else:\n",
    "            episode.append((action,-1))\n",
    "    G = 0\n",
    "    for i, (action, reward) in enumerate(episode):\n",
    "        G = gamma * G + reward\n",
    "        if action == 1:\n",
    "            theta[1] = theta[1] + alpha * (gamma ** i) * G * (1 - softmax(theta))\n",
    "        else:\n",
    "            theta[0] = theta[0] + alpha * (gamma ** i) * G * (0 - softmax(theta))\n",
    "print(theta)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.92758\n"
     ]
    }
   ],
   "source": [
    "tot_reward = 0\n",
    "num_tests = 100000\n",
    "for _ in range(num_tests):\n",
    "    state = 0\n",
    "    num_steps = 0\n",
    "    while num_steps < max_steps_per_episode:\n",
    "        num_steps += 1\n",
    "        action = get_action()\n",
    "        state = next_state(state, action)\n",
    "        if state == 4:\n",
    "            tot_reward += 1\n",
    "            break\n",
    "        else:\n",
    "            tot_reward -= 1\n",
    "print(tot_reward/num_tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45470473754835933, -0.44083660958541837]\n",
      "-13.6285\n"
     ]
    }
   ],
   "source": [
    "new_theta = [0,0]\n",
    "w = 0\n",
    "alpha_theta = 2e-5\n",
    "alpha_w = 2e-4\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    num_steps = 0\n",
    "    episode = []\n",
    "    state = 0\n",
    "    while num_steps < max_steps_per_episode:\n",
    "        num_steps += 1\n",
    "        action = get_action(new_theta)\n",
    "        ns = next_state(state, action)\n",
    "        if ns == 3:\n",
    "            episode.append((state, action,1))\n",
    "            break\n",
    "        else:\n",
    "            episode.append((state, action,-1))\n",
    "            state = ns\n",
    "    G = 0\n",
    "    for i, (state, action, reward) in enumerate(episode):\n",
    "        G = gamma * G + reward\n",
    "        l = G - w * state\n",
    "        w += alpha_w * l * state\n",
    "        if action == 1:\n",
    "            new_theta[1] += alpha_theta * (gamma ** i) * l * (1 - softmax(new_theta))\n",
    "        else:\n",
    "            new_theta[0] += alpha_theta * (gamma ** i) * l * (0 - softmax(new_theta))\n",
    "print(new_theta)\n",
    "tot_reward = 0\n",
    "for _ in range(num_tests):\n",
    "    state = 0\n",
    "    num_steps = 0\n",
    "    while num_steps < max_steps_per_episode:\n",
    "        num_steps += 1\n",
    "        action = get_action(new_theta)\n",
    "        state = next_state(state, action)\n",
    "        if state == 4:\n",
    "            tot_reward += 1\n",
    "            break\n",
    "        else:\n",
    "            tot_reward -= 1\n",
    "print(tot_reward/num_tests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
